{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1a30298",
   "metadata": {},
   "source": [
    "# Fundamentals of Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484db91c",
   "metadata": {},
   "source": [
    "#### Basic yet powerful terms: Mean, Mode, Median, Standard Deviation and Correlation Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2f5bd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9813b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean learning time:  4.6\n",
      "Mean Score:  4.8\n",
      "Median learning time:  4.0\n",
      "Standard Deviation:  3.2\n",
      "Correlation b/w learning hours and scores:  [[1.         0.88964891]\n",
      " [0.88964891 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "learning_hour = [1,2,6,4,10]\n",
    "scores = [3,4,6,5,6]\n",
    "\n",
    "print(\"Mean learning time: \", np.mean(learning_hour))\n",
    "print(\"Mean Score: \", np.mean(scores))\n",
    "print(\"Median learning time: \",np.median(learning_hour))\n",
    "print(\"Standard Deviation: \",np.std(learning_hour))\n",
    "print(\"Correlation b/w learning hours and scores: \",np.corrcoef(learning_hour, scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc64ea09",
   "metadata": {},
   "source": [
    "- **Mean:** is the average of a data set, the sum of the elements divided by the total number of elements.\n",
    "\n",
    "\n",
    "- **Median** is the middle element of the set of elements, if the length is odd, median is middle value of a **sorted copy** of   the array.\n",
    "\n",
    "\n",
    "- **Standard Deviation** is a measure of **how much the data is spread out**, it shows us how much our data is spread out         around the mean.\n",
    "    - Standard Deviation is the square root of the **Variance**.\n",
    "    - Variance is defined as the average of square differences from the mean.\n",
    "    - To calculate variance manually:\n",
    "        1. Compute the mean.\n",
    "        2. Then for each number, subtract the mean and the square the result, i.e. the squared difference\n",
    "        3. Then compute the average of those squared differences.(Mean of those differences)\n",
    "    - So to calculate the Standard Deviation, take the square root of the above output.\n",
    "\n",
    "\n",
    "- **Correlation Coefficient**: When two data sets are strongly linked together, we say they have high correlation.\n",
    "    - Correlation is Positive when the values for the two sets of data increase together.\n",
    "    - It is Negative when one value increases while the other decreases.\n",
    "    - Correlation coefficient is a way to put a value to the relationship.\n",
    "    - Correlation coefficients have a value of b/w -1 and 1:\n",
    "        - 1 is a perfect positive correlation.\n",
    "        - 0 is no correlation meaning the values down't seem linked at all.\n",
    "        - -1 is perfect negative correlation.\n",
    "    - **Correlation is NOT Causation**: it means that correlation b/w two things doesn't prove one thing causes other:\n",
    "        - One event **might** cause the other.\n",
    "        - The other event **might** cause the first to happen.\n",
    "        - They **may** be linked by a different reason.\n",
    "        - Or the result **could** have been random."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a18ee0",
   "metadata": {},
   "source": [
    "## Box Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541adb3d",
   "metadata": {},
   "source": [
    "- A box plot is basically a graph that presents information from a **five-number summary**.\n",
    "\n",
    "\n",
    "- If we look at a box plot diagram (any fully heatured example):\n",
    "    - The end of the box are the first(lower) and third(upper) quartiles - the box spans the so-called interquartile range.\n",
    "        - The first quarytile basically represents the 25th percentile.\n",
    "        - Meaning that 25% of the data points fall below the first quartile.\n",
    "        - The third quartile is the 75th percentile, means 75% of the points in the data fall below the third quartile.\n",
    "    - The **median, marked by the horizontal line** inside the box is the middle value of the dataset, the 50th percentile.\n",
    "        - The median is used instead of mean because it is more robust to outlier value.\n",
    "    - The **whiskers** are the two lines outside the box that extend to to hightest and lowest(max/min) observations in data.\n",
    "\n",
    "\n",
    "- **Five Number Summary**, is made up of these five values: the **maximum value**, the **minimum value**, the **lower             quartile**, the **upper quartile**, and  the **median**. These values are ordered from lowest to highest:\n",
    "    - Minimum Value\n",
    "    - Lower Quartile(Q1/25th percentile)\n",
    "    - Median value(Q2/50th percentile)\n",
    "    - Upper Value(Q3/75th percentile)\n",
    "    - Maximum Value\n",
    "- These five numbers give us the summary of the data as each value describes a specific part of a dataset.\n",
    "\n",
    "\n",
    "#### Interpreting a Box Plot\n",
    "\n",
    "- A **short box plot** tells us that many of our **data points are similar**, we have many **values in a small range**.\n",
    "  On the other hand, a **tall box plot** implies that much of the **data points are quite different**, we have values\n",
    "  that are spreat over a wide range.\n",
    "- A **median value** that is **close to the bottom** tells us that **most of our data points have lower values**.\n",
    "  While a **closer to the top** tells us that **most of our data has higher value**. Basically, **a median line not in the       middle of the box indicates skewed data**.\n",
    "- *What about the length of those whiskers?*\n",
    "  **Long whiskers** tell us that our data has a **high standard deviation and variance**, i.e., the values are spread out and     vary a lot. If there are long whiskers on one side of the box, but not the other, then it's an indication that our data         varies, but only in one direction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb929a8a",
   "metadata": {},
   "source": [
    "## Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd1d719",
   "metadata": {},
   "source": [
    "- **Probability is the numerical chance that something will happen; it tells us how likely it is that some event will occur**.\n",
    "\n",
    "\n",
    "#### Probability and Data Science\n",
    "\n",
    "- Understanding the methods and models needed for data science, like logistic regression which we will encounter in the Machine   Learning section, randomization in A/B testing, or in experimental design, and sample of data are examples of use-cases that   require good understanding of probability.\n",
    "\n",
    "- **Probability of an Event** = (**Number of Ways It can Happen**)/(**Total Number of Outcomes**)\n",
    "\n",
    "#### A. Independent Events\n",
    "- Two events are independent when the outcome of the first event does not influence the outcome of the second event.\n",
    "- **```P(X and Y) = P(X) * P(Y)```**\n",
    "\n",
    "#### B. Dependent Events\n",
    "- Two events are dependent when the outcome of the first event affects the outcome of the second event.\n",
    "- **```P(X and Y) = P(X) * P(Y after X has occured)```**\n",
    "\n",
    "#### C. Mutually Exclusive Events\n",
    "- Two events are mutually exclusive when it is impossible for them to happen together. \n",
    "- e.g. Turning Left and turning Right are mutualy aggressive. They can\\'t happen at once.\n",
    "- ***Except in the world of Quantum Physics***.\n",
    "- **```P(X or Y) = P(X) + P(Y)```**\n",
    "- **```P(A and B) = 0```**\n",
    "\n",
    "#### D. Inclusive Events\n",
    "- Inclusive events are the events that can happen at the same time.\n",
    "- To get the probabilities of an inclusive event:\n",
    "    - We first add the probabilities of the individual events.\n",
    "    - Then subtract the probability of the two events.\n",
    "- **```P(X or Y) = P(X) + P(Y) - P(X and Y)```**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2010c5b4",
   "metadata": {},
   "source": [
    "## Conditional Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4f1d65",
   "metadata": {},
   "source": [
    "- Conditional Probability is ameasure of the probability of an event that another event occered.\n",
    "- It is the probability of one event occuring with some relationship to one or more other events.\n",
    "- **```P(Y|X) = P(X and Y) / P(X)```** \n",
    "    - Say event **X** is that raining outside, there's a 0.3 chance of rain today.\n",
    "    - Event **Y** might be that you will need to go outside with a probability of 0.5.\n",
    "    - A conditional probability would look at these two events, **X AND Y**, in a relationship with one another.\n",
    "- ***P(XandY) = P(X)*P(Y*|*X)*** , this is known as **Bayes Theorem**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438fdc19",
   "metadata": {},
   "source": [
    "### Bayesian Statistics\n",
    "\n",
    "- There are two categories of probabilites: **Frequency Statistics** and **Bayesian Statistics**.\n",
    "- *Bayesian Statistics* is also known as *Bayesian Inference*.\n",
    "- **Bayesian Statistics** is amore general approach to statistics.\n",
    "- It describes the probability of an event based on the previous knowledge of the conditions that might be related to event.\n",
    "- It is based on the **Bayes' Theorem**: *basically a way of finding probabilities when we know certain other probabilities.*\n",
    "- The formula: **```P(A|B) = P(A) * P(B|A) / P(B)```**\n",
    "- This tells us how often A happens given that B happens, written P(A|B), when we have the following information:\n",
    "    - How often B happens given that A happens, written P(B|A).\n",
    "    - How likely A is on its own, written P(A).\n",
    "    - How likely B is on its own, written P(B)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5020b6",
   "metadata": {},
   "source": [
    "### Probability Distributions\n",
    "\n",
    "- A probability distribution is a function that represents the probabilities of all possible values.\n",
    "- By specifying the relative chance of all possible outcomes, probability distributions allow us to understand underlying         trends in data.\n",
    "\n",
    "#### Random Variables\n",
    "\n",
    "- The set of possible valuesfrom a random experiment is called **Random Variable**.\n",
    "- Random Variables can be either discrete or Continuous:\n",
    "    - **Discrete Data**: a.k.a. Discrete Variables can only take specified values. e.g. Rolling a dice.\n",
    "    - **Continuous Data**: a.k.a. Continuous Variables can take any value within a range. This range can be finite or infinite.\n",
    "- *Types of Probability Distributions*:\n",
    "    1. **Discrete probability Distributions**: for Discrete Variables.\n",
    "    2. **Probabity Density Functions**: for Continuous Variables.\n",
    "\n",
    "#### Probability Functions\n",
    "- The probability functions for a *Discrete Random Variable* is often called **Probability Mass Function**.\n",
    "- And for a *Continuous Random Variable* is often called **Probability Density Function (prob. distribution function)**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbac123e",
   "metadata": {},
   "source": [
    "### Types of Distributions\n",
    "\n",
    "\n",
    "#### 1. Uniform Distribution\n",
    "\n",
    "- This is a basic probability distribution where all the values have same probability of occurence within a specified range.\n",
    "- All the values outside that range have probability of 0.\n",
    "- e.g. : Rolling a fair die: Outcomes can range from 1-6, and they all have probability of 1/6. Prob. of getting a 0 or 7 is 0.\n",
    "- Also known as Rectangular Distribution.\n",
    "- The dessity function, f(X), of a variable X that is uniformly distributed is: **f(x) = 1 / (b-a)**, where **a**:-minimum       value and **b**:- maximum value of the possible range of values of **X**.\n",
    "- **Mean** = ***E(X) = (a + b) / 2***\n",
    "- **Variance** = ***V(X) = (b - a)<sup>2</sup> / 12***\n",
    "\n",
    "\n",
    "#### 2. Benoulli Distribution\n",
    "\n",
    "- A Bernoulli distribution is a **discrete** probability distribution.\n",
    "- It is used when a random experiment has **only two outcomes**, **\"success\"** or **failure**.\n",
    "- e.g. **Flipping a coin** has only two outcomes: **heads** nad **tails**.\n",
    "- A random variable ***X***, with a Bernoulli distribution can take value 1 with probability of success ***p***, and value 0     with the probability of failure ***1-p***.\n",
    "- The probability of success and faiulure do not need to be equally likely.\n",
    "- The probability function, ***P(X)***is given by\n",
    "    - ***P(x) = p<sup>x</sup> * (1-p)<sup>(1-x)</sup>***,    where x ∈ (0,1).\n",
    "- **Mean**  =  ***E(X)  =  1 * p + 0 * (1-p)  =  p***\n",
    "- **Variance**  =  ***V(X)  =  E(X<sup>2</sup>) - [E(X)]<sup>2</sup>  =  p - p<sup>2</sup> = p(1-p)***\n",
    "\n",
    "\n",
    "#### 3. Binomial Distribution\n",
    "\n",
    "- A Binomial distribution can be thought of as the probability of having success or failure as outcome in an experiment that is   repeated multiple times.\n",
    "- Binomial distributions must follow these criteria:\n",
    "    - There are **only two possibll outcomes** in a trial-either success or failure.\n",
    "    - The **probability of success** is exactly the same for all trials.\n",
    "    - The **number of observations** or trials is fixed, a total number of n identical trials.\n",
    "    - Each observation **trial is independent**, none of the trials have an effect on the probability of the next trial.\n",
    "- **Mean** = ***E(X) = n * p***\n",
    "- **Variance** = ***V(X) = n * p * (1-p)***; n:= number of trials\n",
    "\n",
    "\n",
    "#### 4. Normal Distribution\n",
    "\n",
    "- A normal distribution, the bell curve or Gaussian Distribution, is a distribution that represents the behavious in most         situtions.\n",
    "- The bells curve is symmetrical, half of the data will fall to the left of the mean value and half will fall to the right of     it.\n",
    "- The number of standard deviation from the mean (distance from mean) is called **standard score** or **z-score**.\n",
    "- Z-scores are a way to compare results froma test to a **\"normal\"** population.\n",
    "- A normal distribution with a mean of 0 and standard deviation of 1 is called a **standard normal ditribution**.\n",
    "- The process of transforming a distribution to one with a mean of 0 and standard deviation of 1 is called **standardizing the   distribution**.\n",
    "- **Mean** = ***E(X) = μ***\n",
    "- **Variance** = ***V(X) = σ<sup>2</sup>***\n",
    "- **Z-score** = ***z = (x - μ) / σ***\n",
    "\n",
    "\n",
    "#### 5. Poisson Distribution\n",
    "\n",
    "- This distrbution gives us the probability of a given **number of events** happening **in a fixed interval of time**.\n",
    "- For a distribution to be called **Poisson Distribution**, the following assumption need to be in place:\n",
    "    - The number of success in two disjint time intervals is independent.\n",
    "    - The probability of a success during a small-time interval is proportional to the entire length of the time interval. The       probability of success in an interval approaches zero as the interval becomes smaller.\n",
    "- **Probability Function = *P(x) = e<sup> - μ</sup> * μ<sup> x</sup> / x!***;       x:= 0,1,2,3...\n",
    "- **Mean = * μ = λ * t***;     λ:= The rate at which an event occurs; t:= is the length of the time interval.\n",
    "\n",
    "\n",
    "#### 6. Exponential Distribution\n",
    "\n",
    "- It allows us to step further from the Poisson Distribution.\n",
    "- It allows us to model the time in between each accident.\n",
    "- The kind of questions that can be answered by modeling waiting times:\n",
    "    - How much time will go by before a major earthquake hits a certain area?\n",
    "    - How long will a car component last before it needs replacement?\n",
    "- **Probability Function = *f(x) = λ * e<sup> - λ x</sup>***;       λ:= mean time between events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e407c9",
   "metadata": {},
   "source": [
    "### Statistical Significance\n",
    "\n",
    "- **Statistical significance is ameasure of weather our findings are meaningful or just a result of random chance.**\n",
    "\n",
    "- Components of Statistical Significance:\n",
    "    1. Hypothesis Testing\n",
    "    2. Normal Distribution\n",
    "    3. p-values\n",
    "    \n",
    "1. Hypothesis Testing\n",
    "    - is a technique for evaluating a theory using data.\n",
    "    - The hypothesis is the researcher's initial belief about the situation before the study.\n",
    "    - The commonly accepted fact is known as ***Nul Hypothesis***.\n",
    "    - While the opposite is known as ***Alternative Hypothesis***.\n",
    "\n",
    "2. Normal Distribution\n",
    "    - **z-test**: A z-test is astatistical technique to test the Null Hypothesis against the Alternative Hypothesis.\n",
    "    - This technique is used when the sample data us normally distributed and the population size is greater than 30. **Why 30?**\n",
    "    - ***Central Limit Theorem*** : According to this theorem as the sample size grows and the number of data points exceeds         30, the samples are considered to be normally distributed.\n",
    "    - z-test are based on z-scores, which tell us where athe sample mean lies compared to the population mean.\n",
    "\n",
    "3. P-value\n",
    "    - The p-value quantifies the rareness in our results.\n",
    "    - It tells us how often we'd see the numercal results of an experiment (z-scores) if the null hypothesis is true and there       are no differences between the groups.\n",
    "    - This mean that we can use the p-values to reach conclusions in significance testing.\n",
    "    - More specifically, we compare the p-value to a **significance level α** to make conclusions about our hypotheses\n",
    "        - **If the p-value is very small** or lower that the **significance level** we chose, it means the numbers would rarely           occur by chance alone, and we can reject the null hypothesis in favour of the alternative hypothesis.\n",
    "        - **If the p-value is greater than or equal to the significance level**, then we fail to reject the null hypothesis.             This doesn't mean we accept the null hypothesis though.\n",
    "    - The choice of ***α*** depends on the situation, **0.05** is the most widely used value across all scientific disciplines.\n",
    "    - This means that *p < 0.05* is the threshold beyond which study results can be declared to be *Statistically Significant*.\n",
    "    - i.e. Its unlikely the results were the result of random chance.\n",
    "    - If we run the experiment 100 times, we'd see these same numbers, or more extreme results, 5 times, assuming the null           hypothesis is true.\n",
    "    - p-value less that 0.05 means **there is less than a 5% chance of seeing our results, or more extreme results, assuming         the null hypothesis is true**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165d6f63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
